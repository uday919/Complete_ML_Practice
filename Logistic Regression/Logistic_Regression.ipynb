{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1835826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fec3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e1bbeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset\n",
    "X,y=make_classification(n_samples=1000,n_features=10,n_classes=2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efdbda61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.964799</td>\n",
       "      <td>-0.066449</td>\n",
       "      <td>0.986768</td>\n",
       "      <td>-0.358079</td>\n",
       "      <td>0.997266</td>\n",
       "      <td>1.181890</td>\n",
       "      <td>-1.615679</td>\n",
       "      <td>-1.210161</td>\n",
       "      <td>-0.628077</td>\n",
       "      <td>1.227274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.916511</td>\n",
       "      <td>-0.566395</td>\n",
       "      <td>-1.008614</td>\n",
       "      <td>0.831617</td>\n",
       "      <td>-1.176962</td>\n",
       "      <td>1.820544</td>\n",
       "      <td>1.752375</td>\n",
       "      <td>-0.984534</td>\n",
       "      <td>0.363896</td>\n",
       "      <td>0.209470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.109484</td>\n",
       "      <td>-0.432774</td>\n",
       "      <td>-0.457649</td>\n",
       "      <td>0.793818</td>\n",
       "      <td>-0.268646</td>\n",
       "      <td>-1.836360</td>\n",
       "      <td>1.239086</td>\n",
       "      <td>-0.246383</td>\n",
       "      <td>-1.058145</td>\n",
       "      <td>-0.297376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.750412</td>\n",
       "      <td>2.023606</td>\n",
       "      <td>1.688159</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>-1.607661</td>\n",
       "      <td>0.184741</td>\n",
       "      <td>-2.619427</td>\n",
       "      <td>-0.357445</td>\n",
       "      <td>-1.473127</td>\n",
       "      <td>-0.190039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.224726</td>\n",
       "      <td>-0.711303</td>\n",
       "      <td>-0.220778</td>\n",
       "      <td>0.117124</td>\n",
       "      <td>1.536061</td>\n",
       "      <td>0.597538</td>\n",
       "      <td>0.348645</td>\n",
       "      <td>-0.939156</td>\n",
       "      <td>0.175915</td>\n",
       "      <td>0.236224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-1.367638</td>\n",
       "      <td>1.462255</td>\n",
       "      <td>-1.154918</td>\n",
       "      <td>-0.290454</td>\n",
       "      <td>-0.413424</td>\n",
       "      <td>0.032396</td>\n",
       "      <td>1.545490</td>\n",
       "      <td>1.428760</td>\n",
       "      <td>1.687092</td>\n",
       "      <td>1.072542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-1.514876</td>\n",
       "      <td>-3.221016</td>\n",
       "      <td>-1.300744</td>\n",
       "      <td>0.395599</td>\n",
       "      <td>-0.527994</td>\n",
       "      <td>1.353069</td>\n",
       "      <td>1.777506</td>\n",
       "      <td>-1.680870</td>\n",
       "      <td>1.798510</td>\n",
       "      <td>0.034272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.674633</td>\n",
       "      <td>1.754933</td>\n",
       "      <td>1.586154</td>\n",
       "      <td>0.018402</td>\n",
       "      <td>-1.514470</td>\n",
       "      <td>0.321593</td>\n",
       "      <td>-2.417694</td>\n",
       "      <td>0.692723</td>\n",
       "      <td>-1.503850</td>\n",
       "      <td>0.225264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.778609</td>\n",
       "      <td>-0.835689</td>\n",
       "      <td>-0.194842</td>\n",
       "      <td>1.097220</td>\n",
       "      <td>0.180071</td>\n",
       "      <td>-0.272933</td>\n",
       "      <td>-0.533188</td>\n",
       "      <td>-0.497354</td>\n",
       "      <td>2.472138</td>\n",
       "      <td>0.867187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.248454</td>\n",
       "      <td>-1.003439</td>\n",
       "      <td>0.360460</td>\n",
       "      <td>-0.331352</td>\n",
       "      <td>1.389764</td>\n",
       "      <td>-1.345210</td>\n",
       "      <td>-0.740875</td>\n",
       "      <td>0.773240</td>\n",
       "      <td>0.185734</td>\n",
       "      <td>1.416412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.964799 -0.066449  0.986768 -0.358079  0.997266  1.181890 -1.615679   \n",
       "1   -0.916511 -0.566395 -1.008614  0.831617 -1.176962  1.820544  1.752375   \n",
       "2   -0.109484 -0.432774 -0.457649  0.793818 -0.268646 -1.836360  1.239086   \n",
       "3    1.750412  2.023606  1.688159  0.006800 -1.607661  0.184741 -2.619427   \n",
       "4   -0.224726 -0.711303 -0.220778  0.117124  1.536061  0.597538  0.348645   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995 -1.367638  1.462255 -1.154918 -0.290454 -0.413424  0.032396  1.545490   \n",
       "996 -1.514876 -3.221016 -1.300744  0.395599 -0.527994  1.353069  1.777506   \n",
       "997  1.674633  1.754933  1.586154  0.018402 -1.514470  0.321593 -2.417694   \n",
       "998 -0.778609 -0.835689 -0.194842  1.097220  0.180071 -0.272933 -0.533188   \n",
       "999  0.248454 -1.003439  0.360460 -0.331352  1.389764 -1.345210 -0.740875   \n",
       "\n",
       "            7         8         9  \n",
       "0   -1.210161 -0.628077  1.227274  \n",
       "1   -0.984534  0.363896  0.209470  \n",
       "2   -0.246383 -1.058145 -0.297376  \n",
       "3   -0.357445 -1.473127 -0.190039  \n",
       "4   -0.939156  0.175915  0.236224  \n",
       "..        ...       ...       ...  \n",
       "995  1.428760  1.687092  1.072542  \n",
       "996 -1.680870  1.798510  0.034272  \n",
       "997  0.692723 -1.503850  0.225264  \n",
       "998 -0.497354  2.472138  0.867187  \n",
       "999  0.773240  0.185734  1.416412  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f393f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762924ce",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12e4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c56a5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3104b4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1\n",
      " 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0\n",
      " 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1\n",
      " 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 0\n",
      " 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1\n",
      " 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 0 1 1\n",
      " 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred=logistic.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb7f993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.74481865e-01, 2.25518135e-01],\n",
       "       [3.36701953e-02, 9.66329805e-01],\n",
       "       [6.70684311e-01, 3.29315689e-01],\n",
       "       [7.98688284e-02, 9.20131172e-01],\n",
       "       [9.76617515e-01, 2.33824847e-02],\n",
       "       [4.13590037e-02, 9.58640996e-01],\n",
       "       [9.79029806e-01, 2.09701936e-02],\n",
       "       [9.59367633e-01, 4.06323668e-02],\n",
       "       [8.08516510e-01, 1.91483490e-01],\n",
       "       [6.84961496e-01, 3.15038504e-01],\n",
       "       [9.13670314e-01, 8.63296857e-02],\n",
       "       [2.63599422e-01, 7.36400578e-01],\n",
       "       [5.25846966e-01, 4.74153034e-01],\n",
       "       [2.11919907e-01, 7.88080093e-01],\n",
       "       [7.93598597e-01, 2.06401403e-01],\n",
       "       [9.46623760e-01, 5.33762402e-02],\n",
       "       [2.62972095e-02, 9.73702790e-01],\n",
       "       [3.24226362e-01, 6.75773638e-01],\n",
       "       [3.14809449e-01, 6.85190551e-01],\n",
       "       [2.04954712e-01, 7.95045288e-01],\n",
       "       [5.04587814e-01, 4.95412186e-01],\n",
       "       [9.66703959e-01, 3.32960407e-02],\n",
       "       [2.00518184e-01, 7.99481816e-01],\n",
       "       [7.77899761e-01, 2.22100239e-01],\n",
       "       [8.72991320e-01, 1.27008680e-01],\n",
       "       [4.01992876e-02, 9.59800712e-01],\n",
       "       [9.21219173e-01, 7.87808267e-02],\n",
       "       [8.14309281e-01, 1.85690719e-01],\n",
       "       [4.84332824e-01, 5.15667176e-01],\n",
       "       [3.45972984e-01, 6.54027016e-01],\n",
       "       [6.82537540e-02, 9.31746246e-01],\n",
       "       [5.40131363e-04, 9.99459869e-01],\n",
       "       [9.69329547e-01, 3.06704527e-02],\n",
       "       [9.72909700e-01, 2.70903002e-02],\n",
       "       [9.42368579e-01, 5.76314206e-02],\n",
       "       [5.19297868e-01, 4.80702132e-01],\n",
       "       [8.46485360e-02, 9.15351464e-01],\n",
       "       [3.25973489e-01, 6.74026511e-01],\n",
       "       [4.76896441e-01, 5.23103559e-01],\n",
       "       [1.53792182e-04, 9.99846208e-01],\n",
       "       [9.15876864e-01, 8.41231355e-02],\n",
       "       [8.64941639e-02, 9.13505836e-01],\n",
       "       [4.79534466e-01, 5.20465534e-01],\n",
       "       [9.35684881e-01, 6.43151186e-02],\n",
       "       [9.77892432e-01, 2.21075678e-02],\n",
       "       [5.85647729e-01, 4.14352271e-01],\n",
       "       [1.57850274e-02, 9.84214973e-01],\n",
       "       [7.62153473e-02, 9.23784653e-01],\n",
       "       [1.34856191e-02, 9.86514381e-01],\n",
       "       [5.30434207e-02, 9.46956579e-01],\n",
       "       [8.06446491e-01, 1.93553509e-01],\n",
       "       [4.80640441e-03, 9.95193596e-01],\n",
       "       [5.04842439e-01, 4.95157561e-01],\n",
       "       [8.68426696e-01, 1.31573304e-01],\n",
       "       [8.92672785e-03, 9.91073272e-01],\n",
       "       [5.92496250e-01, 4.07503750e-01],\n",
       "       [1.57436250e-01, 8.42563750e-01],\n",
       "       [9.76377528e-01, 2.36224722e-02],\n",
       "       [9.85841380e-02, 9.01415862e-01],\n",
       "       [9.04180754e-01, 9.58192457e-02],\n",
       "       [6.72500548e-03, 9.93274995e-01],\n",
       "       [6.94841326e-01, 3.05158674e-01],\n",
       "       [7.57556928e-01, 2.42443072e-01],\n",
       "       [3.10058692e-02, 9.68994131e-01],\n",
       "       [3.06678156e-01, 6.93321844e-01],\n",
       "       [1.74768485e-01, 8.25231515e-01],\n",
       "       [8.36521054e-01, 1.63478946e-01],\n",
       "       [8.97502104e-01, 1.02497896e-01],\n",
       "       [3.36206495e-01, 6.63793505e-01],\n",
       "       [1.63594256e-01, 8.36405744e-01],\n",
       "       [3.22760752e-01, 6.77239248e-01],\n",
       "       [4.48407621e-02, 9.55159238e-01],\n",
       "       [2.14636531e-04, 9.99785363e-01],\n",
       "       [9.68626945e-01, 3.13730548e-02],\n",
       "       [1.85288140e-01, 8.14711860e-01],\n",
       "       [8.76098052e-01, 1.23901948e-01],\n",
       "       [9.74553011e-01, 2.54469887e-02],\n",
       "       [1.69197167e-03, 9.98308028e-01],\n",
       "       [9.42492972e-01, 5.75070276e-02],\n",
       "       [1.66995263e-01, 8.33004737e-01],\n",
       "       [7.93679632e-01, 2.06320368e-01],\n",
       "       [9.40837464e-01, 5.91625357e-02],\n",
       "       [1.01615314e-01, 8.98384686e-01],\n",
       "       [8.74076764e-01, 1.25923236e-01],\n",
       "       [2.28543145e-04, 9.99771457e-01],\n",
       "       [8.78527123e-01, 1.21472877e-01],\n",
       "       [8.44947807e-01, 1.55052193e-01],\n",
       "       [8.53359591e-01, 1.46640409e-01],\n",
       "       [8.69064992e-01, 1.30935008e-01],\n",
       "       [1.28583877e-01, 8.71416123e-01],\n",
       "       [2.73400137e-03, 9.97265999e-01],\n",
       "       [2.14411341e-02, 9.78558866e-01],\n",
       "       [1.08234081e-01, 8.91765919e-01],\n",
       "       [2.63736527e-01, 7.36263473e-01],\n",
       "       [5.78022690e-02, 9.42197731e-01],\n",
       "       [2.16043961e-01, 7.83956039e-01],\n",
       "       [9.32822742e-01, 6.71772580e-02],\n",
       "       [9.41557827e-01, 5.84421729e-02],\n",
       "       [4.08775347e-01, 5.91224653e-01],\n",
       "       [9.17169218e-01, 8.28307822e-02],\n",
       "       [4.74766726e-03, 9.95252333e-01],\n",
       "       [9.38740890e-01, 6.12591101e-02],\n",
       "       [1.56657301e-02, 9.84334270e-01],\n",
       "       [9.97834478e-01, 2.16552153e-03],\n",
       "       [9.91498842e-01, 8.50115780e-03],\n",
       "       [2.95811194e-01, 7.04188806e-01],\n",
       "       [9.79658129e-01, 2.03418708e-02],\n",
       "       [4.24497885e-03, 9.95755021e-01],\n",
       "       [4.46640159e-01, 5.53359841e-01],\n",
       "       [1.04695114e-01, 8.95304886e-01],\n",
       "       [1.74853656e-01, 8.25146344e-01],\n",
       "       [6.03245449e-02, 9.39675455e-01],\n",
       "       [6.56140824e-02, 9.34385918e-01],\n",
       "       [1.19932755e-01, 8.80067245e-01],\n",
       "       [8.58139148e-03, 9.91418609e-01],\n",
       "       [8.59877793e-01, 1.40122207e-01],\n",
       "       [6.84720111e-01, 3.15279889e-01],\n",
       "       [1.95239503e-01, 8.04760497e-01],\n",
       "       [9.82842411e-01, 1.71575890e-02],\n",
       "       [9.47845022e-01, 5.21549784e-02],\n",
       "       [6.97673013e-04, 9.99302327e-01],\n",
       "       [3.92559718e-02, 9.60744028e-01],\n",
       "       [9.40312854e-01, 5.96871456e-02],\n",
       "       [2.89286381e-02, 9.71071362e-01],\n",
       "       [5.42289824e-02, 9.45771018e-01],\n",
       "       [1.63545398e-01, 8.36454602e-01],\n",
       "       [2.30250688e-03, 9.97697493e-01],\n",
       "       [1.31065468e-01, 8.68934532e-01],\n",
       "       [7.18456043e-02, 9.28154396e-01],\n",
       "       [5.19761272e-03, 9.94802387e-01],\n",
       "       [1.66745837e-01, 8.33254163e-01],\n",
       "       [8.64726781e-01, 1.35273219e-01],\n",
       "       [2.03825685e-01, 7.96174315e-01],\n",
       "       [3.85209992e-02, 9.61479001e-01],\n",
       "       [4.25742886e-01, 5.74257114e-01],\n",
       "       [1.22170814e-01, 8.77829186e-01],\n",
       "       [9.69782987e-01, 3.02170132e-02],\n",
       "       [8.44239030e-01, 1.55760970e-01],\n",
       "       [9.51010813e-01, 4.89891866e-02],\n",
       "       [3.65223925e-02, 9.63477607e-01],\n",
       "       [2.97238616e-01, 7.02761384e-01],\n",
       "       [9.83931108e-01, 1.60688920e-02],\n",
       "       [8.50485458e-01, 1.49514542e-01],\n",
       "       [9.69227221e-01, 3.07727794e-02],\n",
       "       [5.70768012e-01, 4.29231988e-01],\n",
       "       [6.08976444e-01, 3.91023556e-01],\n",
       "       [1.52019067e-03, 9.98479809e-01],\n",
       "       [9.05745569e-01, 9.42544308e-02],\n",
       "       [9.84756939e-01, 1.52430607e-02],\n",
       "       [9.88123177e-01, 1.18768231e-02],\n",
       "       [2.69251140e-02, 9.73074886e-01],\n",
       "       [9.93780698e-01, 6.21930198e-03],\n",
       "       [9.23254454e-01, 7.67455462e-02],\n",
       "       [4.96000594e-01, 5.03999406e-01],\n",
       "       [9.29593709e-01, 7.04062907e-02],\n",
       "       [9.83111918e-01, 1.68880817e-02],\n",
       "       [3.74697480e-03, 9.96253025e-01],\n",
       "       [9.41062693e-01, 5.89373066e-02],\n",
       "       [4.83202797e-01, 5.16797203e-01],\n",
       "       [1.28935173e-01, 8.71064827e-01],\n",
       "       [9.66521035e-01, 3.34789653e-02],\n",
       "       [9.51215587e-02, 9.04878441e-01],\n",
       "       [8.98677902e-01, 1.01322098e-01],\n",
       "       [9.34913945e-01, 6.50860555e-02],\n",
       "       [8.83540452e-01, 1.16459548e-01],\n",
       "       [7.75754015e-01, 2.24245985e-01],\n",
       "       [8.74341146e-01, 1.25658854e-01],\n",
       "       [8.47578762e-01, 1.52421238e-01],\n",
       "       [9.62575606e-01, 3.74243942e-02],\n",
       "       [2.72316024e-01, 7.27683976e-01],\n",
       "       [1.02520173e-01, 8.97479827e-01],\n",
       "       [5.00237888e-01, 4.99762112e-01],\n",
       "       [8.54022574e-01, 1.45977426e-01],\n",
       "       [9.18044055e-01, 8.19559450e-02],\n",
       "       [1.42417516e-01, 8.57582484e-01],\n",
       "       [5.78345565e-02, 9.42165444e-01],\n",
       "       [8.08097044e-01, 1.91902956e-01],\n",
       "       [5.20477079e-01, 4.79522921e-01],\n",
       "       [1.34065429e-01, 8.65934571e-01],\n",
       "       [9.08221455e-02, 9.09177855e-01],\n",
       "       [8.49746926e-03, 9.91502531e-01],\n",
       "       [2.60308357e-01, 7.39691643e-01],\n",
       "       [5.84156069e-02, 9.41584393e-01],\n",
       "       [3.63803552e-02, 9.63619645e-01],\n",
       "       [1.19269549e-01, 8.80730451e-01],\n",
       "       [7.89893915e-01, 2.10106085e-01],\n",
       "       [8.43223196e-01, 1.56776804e-01],\n",
       "       [9.98692315e-01, 1.30768462e-03],\n",
       "       [8.78879748e-01, 1.21120252e-01],\n",
       "       [3.56788101e-02, 9.64321190e-01],\n",
       "       [6.03056823e-01, 3.96943177e-01],\n",
       "       [9.86431468e-01, 1.35685316e-02],\n",
       "       [7.93147418e-01, 2.06852582e-01],\n",
       "       [8.47471429e-01, 1.52528571e-01],\n",
       "       [1.13681024e-01, 8.86318976e-01],\n",
       "       [8.19144936e-01, 1.80855064e-01],\n",
       "       [8.96157436e-01, 1.03842564e-01],\n",
       "       [9.08684103e-02, 9.09131590e-01],\n",
       "       [1.34430955e-02, 9.86556905e-01],\n",
       "       [6.36423872e-03, 9.93635761e-01],\n",
       "       [8.98003490e-01, 1.01996510e-01],\n",
       "       [1.42697682e-02, 9.85730232e-01],\n",
       "       [6.47051534e-01, 3.52948466e-01],\n",
       "       [6.45803242e-01, 3.54196758e-01],\n",
       "       [8.98932746e-01, 1.01067254e-01],\n",
       "       [3.98254483e-01, 6.01745517e-01],\n",
       "       [4.78063005e-02, 9.52193700e-01],\n",
       "       [1.25482536e-01, 8.74517464e-01],\n",
       "       [4.58966773e-04, 9.99541033e-01],\n",
       "       [1.81793809e-01, 8.18206191e-01],\n",
       "       [9.76613816e-01, 2.33861841e-02],\n",
       "       [9.05274286e-01, 9.47257137e-02],\n",
       "       [7.81835426e-01, 2.18164574e-01],\n",
       "       [9.35072370e-01, 6.49276298e-02],\n",
       "       [9.77101449e-01, 2.28985506e-02],\n",
       "       [4.05115858e-01, 5.94884142e-01],\n",
       "       [9.51059930e-01, 4.89400698e-02],\n",
       "       [1.38472467e-03, 9.98615275e-01],\n",
       "       [8.12440196e-01, 1.87559804e-01],\n",
       "       [2.25592515e-01, 7.74407485e-01],\n",
       "       [2.36374312e-01, 7.63625688e-01],\n",
       "       [8.08299917e-01, 1.91700083e-01],\n",
       "       [9.36603168e-01, 6.33968322e-02],\n",
       "       [1.88735249e-02, 9.81126475e-01],\n",
       "       [1.77460025e-01, 8.22539975e-01],\n",
       "       [2.46437562e-02, 9.75356244e-01],\n",
       "       [8.70664788e-01, 1.29335212e-01],\n",
       "       [9.63075851e-04, 9.99036924e-01],\n",
       "       [8.29865504e-02, 9.17013450e-01],\n",
       "       [9.78392869e-01, 2.16071311e-02],\n",
       "       [9.69095602e-01, 3.09043980e-02],\n",
       "       [7.81409686e-01, 2.18590314e-01],\n",
       "       [9.96733275e-01, 3.26672513e-03],\n",
       "       [9.57755578e-01, 4.22444220e-02],\n",
       "       [8.04248877e-01, 1.95751123e-01],\n",
       "       [9.61517522e-01, 3.84824778e-02],\n",
       "       [9.97874659e-01, 2.12534085e-03],\n",
       "       [9.24711686e-01, 7.52883138e-02],\n",
       "       [2.42346010e-02, 9.75765399e-01],\n",
       "       [1.35493128e-01, 8.64506872e-01],\n",
       "       [9.93125860e-01, 6.87414044e-03],\n",
       "       [3.44926809e-03, 9.96550732e-01],\n",
       "       [7.44652070e-01, 2.55347930e-01],\n",
       "       [1.36444131e-01, 8.63555869e-01],\n",
       "       [2.40979535e-02, 9.75902046e-01],\n",
       "       [8.43426032e-01, 1.56573968e-01],\n",
       "       [1.45788436e-04, 9.99854212e-01],\n",
       "       [9.40089263e-01, 5.99107368e-02],\n",
       "       [1.05127669e-02, 9.89487233e-01],\n",
       "       [7.86959717e-01, 2.13040283e-01],\n",
       "       [7.24052243e-02, 9.27594776e-01],\n",
       "       [4.59900226e-01, 5.40099774e-01],\n",
       "       [4.78129992e-01, 5.21870008e-01],\n",
       "       [9.84777199e-01, 1.52228013e-02],\n",
       "       [9.27077179e-01, 7.29228213e-02],\n",
       "       [6.48952060e-03, 9.93510479e-01],\n",
       "       [5.64521972e-02, 9.43547803e-01],\n",
       "       [3.32902546e-02, 9.66709745e-01],\n",
       "       [2.84423727e-03, 9.97155763e-01],\n",
       "       [9.84839839e-01, 1.51601607e-02],\n",
       "       [2.32776846e-01, 7.67223154e-01],\n",
       "       [5.81291922e-01, 4.18708078e-01],\n",
       "       [6.14520121e-02, 9.38547988e-01],\n",
       "       [2.20628779e-02, 9.77937122e-01],\n",
       "       [9.97792652e-01, 2.20734794e-03],\n",
       "       [9.69145599e-01, 3.08544007e-02],\n",
       "       [6.10738877e-01, 3.89261123e-01],\n",
       "       [4.52029934e-03, 9.95479701e-01],\n",
       "       [5.22485488e-03, 9.94775145e-01],\n",
       "       [8.38893325e-01, 1.61106675e-01],\n",
       "       [2.94097052e-02, 9.70590295e-01],\n",
       "       [2.44818311e-02, 9.75518169e-01],\n",
       "       [5.04737096e-01, 4.95262904e-01],\n",
       "       [9.96970942e-01, 3.02905783e-03],\n",
       "       [4.38371748e-01, 5.61628252e-01],\n",
       "       [7.55540093e-01, 2.44459907e-01],\n",
       "       [7.21771966e-01, 2.78228034e-01],\n",
       "       [9.15380208e-01, 8.46197921e-02],\n",
       "       [9.55610942e-01, 4.43890578e-02],\n",
       "       [1.49460460e-01, 8.50539540e-01],\n",
       "       [4.73409051e-01, 5.26590949e-01],\n",
       "       [8.82431144e-01, 1.17568856e-01],\n",
       "       [1.02707612e-02, 9.89729239e-01],\n",
       "       [9.86046846e-01, 1.39531536e-02],\n",
       "       [1.41032967e-01, 8.58967033e-01],\n",
       "       [1.44358323e-01, 8.55641677e-01],\n",
       "       [4.31392623e-04, 9.99568607e-01],\n",
       "       [8.21144889e-01, 1.78855111e-01],\n",
       "       [9.60789878e-01, 3.92101221e-02],\n",
       "       [7.05652583e-03, 9.92943474e-01],\n",
       "       [8.69526443e-01, 1.30473557e-01],\n",
       "       [4.76296467e-02, 9.52370353e-01],\n",
       "       [3.64455780e-01, 6.35544220e-01],\n",
       "       [7.16395657e-01, 2.83604343e-01],\n",
       "       [4.75936227e-01, 5.24063773e-01],\n",
       "       [2.76519062e-01, 7.23480938e-01],\n",
       "       [1.77151018e-01, 8.22848982e-01],\n",
       "       [3.87696775e-01, 6.12303225e-01],\n",
       "       [8.73576301e-02, 9.12642370e-01],\n",
       "       [8.74641465e-01, 1.25358535e-01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd04ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7214eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8466666666666667\n",
      "[[118  17]\n",
      " [ 29 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.84       135\n",
      "           1       0.89      0.82      0.86       165\n",
      "\n",
      "    accuracy                           0.85       300\n",
      "   macro avg       0.85      0.85      0.85       300\n",
      "weighted avg       0.85      0.85      0.85       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score=accuracy_score(y_test,y_pred)\n",
    "print(score)\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a0de8",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65502cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()\n",
    "penalty=['11','l2','elasticnet']\n",
    "c_values=[100,10,1.0,0.1,0.01]\n",
    "solver=['newton-cg','lbfgs','liblinear','sag','saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06e941c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params=dict(penalty=penalty,C=c_values,solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75ebae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv=StratifiedKFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45fc4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GridSearchCV - to find parameeters best fit for this dataset\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid=GridSearchCV(estimator=model,param_grid=params,scoring='accuracy',cv=cv,n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32ed4bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                         'penalty': ['11', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "979c87e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "250 fits failed out of a total of 375.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "125 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got 11.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.87\n",
      " 0.87       0.87       0.87       0.87              nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.87       0.87       0.87       0.87\n",
      " 0.87              nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.87\n",
      " 0.87       0.87       0.87       0.87              nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.87285714 0.87285714 0.87428571 0.87285714\n",
      " 0.87285714        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.87857143\n",
      " 0.87714286 0.87714286 0.87857143 0.87857143        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                         'penalty': ['11', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ac8aa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64cb15f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8785714285714287"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc39de4",
   "metadata": {},
   "source": [
    "# Randomized SearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "672c346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model=LogisticRegression()\n",
    "randomcv=RandomizedSearchCV(estimator=model,param_distributions=params,cv=5,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef8cfb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got 11.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/udaykiran/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [ nan  nan  nan 0.87  nan  nan  nan  nan  nan 0.87]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "                   param_distributions={'C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                                        'penalty': ['11', 'l2', 'elasticnet'],\n",
       "                                        'solver': ['newton-cg', 'lbfgs',\n",
       "                                                   'liblinear', 'sag',\n",
       "                                                   'saga']},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92c6fce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8699999999999999"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31950edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'lbfgs', 'penalty': 'l2', 'C': 1.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83a1941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95d5eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=randomcv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bd371e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8466666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84       147\n",
      "           1       0.82      0.89      0.86       153\n",
      "\n",
      "    accuracy                           0.85       300\n",
      "   macro avg       0.85      0.85      0.85       300\n",
      "weighted avg       0.85      0.85      0.85       300\n",
      "\n",
      "[[118  29]\n",
      " [ 17 136]]\n"
     ]
    }
   ],
   "source": [
    "score=accuracy_score(y_pred,y_test)\n",
    "print(score)\n",
    "print(classification_report(y_pred,y_test))\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f49dc",
   "metadata": {},
   "source": [
    "# Logistic Regression for Multiclass Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dedc4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset\n",
    "X,y=make_classification(n_samples=1000,n_features=10,n_informative=3,n_classes=3,random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27f136d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.28613186, -0.64833414,  1.04411477, ..., -1.3164116 ,\n",
       "         1.01191003, -0.89806282],\n",
       "       [-0.22222406,  2.083232  ,  1.19111402, ...,  0.98140271,\n",
       "        -1.62879759,  1.37759419],\n",
       "       [-0.43196264,  0.37574543, -1.37033375, ...,  1.2926021 ,\n",
       "         0.925545  ,  0.23270542],\n",
       "       ...,\n",
       "       [-0.16384636, -0.41072503,  0.73908587, ...,  0.55830515,\n",
       "         1.08971786, -0.26627295],\n",
       "       [ 1.74969059, -1.12416838,  0.19980683, ...,  0.75255654,\n",
       "         0.32229436, -0.17334302],\n",
       "       [-0.24755583, -1.1705942 , -1.14058569, ...,  0.2063625 ,\n",
       "         1.84351802, -0.81483138]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e95d2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 1, 0, 1, 0, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2,\n",
       "       2, 1, 1, 0, 2, 0, 2, 1, 2, 1, 2, 2, 0, 1, 2, 1, 1, 2, 1, 1, 2, 2,\n",
       "       0, 2, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0, 2, 2, 0, 1, 1, 2, 0, 0, 1, 0,\n",
       "       0, 1, 2, 2, 0, 1, 2, 2, 1, 2, 0, 2, 0, 0, 1, 0, 2, 0, 2, 0, 0, 2,\n",
       "       1, 2, 0, 0, 2, 0, 1, 0, 2, 0, 2, 1, 0, 0, 2, 2, 0, 2, 2, 0, 1, 0,\n",
       "       1, 0, 1, 2, 1, 1, 1, 2, 0, 2, 0, 2, 1, 1, 0, 0, 1, 1, 2, 2, 1, 2,\n",
       "       0, 1, 2, 2, 0, 2, 2, 0, 0, 1, 0, 2, 0, 1, 2, 0, 2, 1, 1, 0, 2, 1,\n",
       "       0, 2, 2, 2, 2, 2, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       2, 2, 1, 2, 2, 2, 2, 0, 1, 0, 1, 0, 2, 2, 2, 1, 1, 0, 0, 0, 2, 0,\n",
       "       0, 0, 1, 0, 2, 1, 0, 2, 2, 1, 1, 1, 1, 2, 0, 1, 2, 2, 1, 1, 0, 2,\n",
       "       2, 1, 0, 2, 2, 1, 0, 1, 2, 0, 2, 1, 0, 0, 1, 2, 0, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 2, 2, 1, 0, 1, 1, 2, 2, 2, 2, 0, 1, 0,\n",
       "       0, 2, 2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 0, 0, 1, 0, 1, 2, 1, 0, 1, 0,\n",
       "       2, 0, 1, 0, 0, 2, 2, 1, 0, 2, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0,\n",
       "       1, 2, 0, 0, 2, 0, 0, 2, 1, 0, 2, 0, 0, 1, 0, 0, 1, 2, 1, 1, 1, 1,\n",
       "       2, 1, 1, 1, 2, 2, 1, 2, 0, 1, 0, 2, 2, 1, 2, 0, 0, 2, 1, 1, 2, 1,\n",
       "       1, 0, 2, 2, 0, 2, 1, 0, 0, 2, 2, 1, 0, 2, 0, 1, 0, 2, 2, 1, 2, 2,\n",
       "       0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 2, 1, 0, 2, 2, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 1, 2, 0, 1,\n",
       "       1, 2, 2, 0, 2, 1, 2, 0, 1, 1, 2, 1, 0, 2, 1, 1, 2, 1, 0, 2, 1, 0,\n",
       "       0, 0, 2, 1, 0, 1, 0, 2, 0, 0, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1,\n",
       "       0, 2, 2, 2, 0, 2, 0, 0, 2, 1, 0, 1, 1, 1, 1, 2, 2, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1,\n",
       "       0, 0, 2, 1, 2, 2, 1, 0, 0, 2, 2, 2, 1, 1, 0, 2, 2, 1, 0, 1, 2, 1,\n",
       "       1, 0, 0, 1, 0, 2, 2, 1, 2, 2, 0, 0, 1, 1, 0, 0, 1, 2, 2, 0, 2, 2,\n",
       "       0, 2, 1, 0, 1, 2, 1, 0, 1, 0, 0, 2, 1, 1, 0, 0, 2, 2, 2, 0, 0, 0,\n",
       "       1, 0, 1, 1, 2, 0, 1, 2, 1, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 2, 0, 1, 2, 0, 2, 1, 0, 2, 1, 2, 2, 0, 2, 1, 0, 0, 0, 2, 0,\n",
       "       2, 2, 1, 2, 0, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 2, 2, 0, 2, 2,\n",
       "       2, 0, 2, 1, 0, 2, 2, 1, 0, 2, 2, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 2, 2, 1, 2, 1, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 2,\n",
       "       0, 1, 2, 2, 0, 1, 0, 0, 2, 0, 0, 2, 2, 2, 1, 2, 2, 1, 0, 2, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 2, 2, 1, 1, 2, 2, 0, 1, 2, 0, 2, 2, 0, 2, 2,\n",
       "       1, 2, 2, 2, 1, 0, 0, 0, 1, 0, 1, 1, 2, 1, 2, 1, 2, 0, 0, 2, 0, 2,\n",
       "       1, 1, 0, 1, 0, 2, 1, 2, 1, 2, 0, 0, 0, 0, 1, 0, 1, 2, 0, 2, 1, 1,\n",
       "       2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 1, 0, 0,\n",
       "       2, 0, 1, 2, 0, 1, 0, 2, 1, 1, 1, 2, 1, 1, 2, 0, 2, 2, 0, 2, 1, 1,\n",
       "       1, 2, 2, 2, 0, 2, 1, 2, 1, 1, 0, 2, 1, 1, 2, 2, 2, 1, 2, 1, 0, 2,\n",
       "       0, 1, 0, 1, 2, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 0, 0, 0, 2,\n",
       "       1, 1, 1, 0, 0, 2, 1, 2, 1, 2, 2, 2, 2, 1, 0, 1, 0, 2, 2, 2, 2, 0,\n",
       "       1, 0, 2, 0, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 1, 2, 2, 2,\n",
       "       2, 0, 0, 2, 2, 2, 2, 0, 2, 1, 1, 0, 2, 0, 2, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 2, 2, 1, 1, 0, 0, 1, 1, 0, 0, 2, 2, 2, 0, 2, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 0, 2, 1, 1, 1, 2, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 2, 2, 1, 0, 2, 2, 2, 0, 1, 1, 2, 1, 2, 2, 2, 1, 0, 1,\n",
       "       2, 0, 2, 0, 1, 2, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c97eb787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1903ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic=LogisticRegression(multi_class='ovr')\n",
    "logistic.fit(X_train,y_train)\n",
    "y_pred=logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49daa12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 0, 0, 0, 2, 0, 2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1,\n",
       "       1, 1, 1, 0, 0, 0, 2, 1, 0, 2, 2, 1, 2, 0, 0, 2, 2, 1, 2, 2, 2, 1,\n",
       "       2, 0, 1, 2, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       2, 1, 0, 1, 0, 1, 2, 1, 2, 2, 1, 0, 1, 0, 1, 0, 1, 2, 2, 0, 1, 2,\n",
       "       2, 1, 1, 2, 2, 0, 0, 0, 2, 2, 0, 1, 2, 1, 2, 1, 0, 2, 0, 2, 0, 1,\n",
       "       2, 1, 2, 2, 1, 1, 1, 1, 2, 0, 2, 0, 1, 2, 0, 0, 2, 2, 2, 1, 2, 0,\n",
       "       2, 2, 0, 0, 0, 2, 0, 2, 0, 1, 2, 1, 1, 2, 0, 0, 1, 1, 2, 2, 2, 1,\n",
       "       2, 0, 2, 2, 2, 1, 0, 2, 0, 0, 2, 0, 2, 0, 0, 1, 2, 0, 1, 1, 1, 1,\n",
       "       0, 2, 1, 0, 0, 1, 2, 2, 2, 2, 2, 0, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1,\n",
       "       0, 0, 1, 2, 2, 0, 0, 2, 1, 2, 1, 0, 0, 2, 1, 1, 1, 2, 2, 1, 2, 1,\n",
       "       0, 1, 0, 0, 1, 0, 2, 1, 0, 2, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 1, 0, 0, 1, 0, 2,\n",
       "       1, 2, 0, 0, 0, 2, 2, 1, 2, 0, 1, 1, 0, 0, 0, 1, 0, 2, 2, 0, 2, 0,\n",
       "       0, 0, 1, 1, 2, 0, 1, 2, 2, 0, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab44e4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84        97\n",
      "           1       0.73      0.81      0.77        91\n",
      "           2       0.82      0.71      0.76       112\n",
      "\n",
      "    accuracy                           0.79       300\n",
      "   macro avg       0.79      0.79      0.79       300\n",
      "weighted avg       0.79      0.79      0.79       300\n",
      "\n",
      "[[84  3 10]\n",
      " [10 74  7]\n",
      " [ 8 25 79]]\n"
     ]
    }
   ],
   "source": [
    "score=accuracy_score(y_pred,y_test)\n",
    "print(score)\n",
    "print(classification_report(y_pred,y_test))\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf61c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
